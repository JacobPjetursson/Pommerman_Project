{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import algo\n",
    "\n",
    "#from arguments import get_args\n",
    "from envs import make_vec_envs\n",
    "from models import create_policy\n",
    "from rollout_storage import RolloutStorage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_algo = 'a2c'\n",
    "load = True\n",
    "\n",
    "arg_num_steps = 10\n",
    "arg_num_processes = 1\n",
    "arg_num_frames = 5e7\n",
    "arg_lr_schedule = 500000\n",
    "arg_seed = 1\n",
    "arg_cuda = True\n",
    "\n",
    "arg_log_dir = '/tmp/gym/'\n",
    "arg_save_dir = '/trained_models/'\n",
    "\n",
    "arg_load_path = './trained_models/a2c/PommeFFACompetitionFast-v0.pt'\n",
    "\n",
    "arg_env_name = 'PommeFFACompetitionFast-v0'\n",
    "\n",
    "arg_lr = 2.5e-4\n",
    "arg_eps = 1e-5\n",
    "arg_alpha = 0.99\n",
    "arg_gamma = 0.9\n",
    "arg_tau = 0.95\n",
    "arg_no_norm = True\n",
    "arg_num_stack = 1\n",
    "arg_clip_param = 0.2\n",
    "\n",
    "arg_value_loss_coef = 0.5\n",
    "arg_loss_coef = 0.5\n",
    "arg_entropy_coef = 0.01\n",
    "\n",
    "arg_use_gae = True\n",
    "\n",
    "arg_max_grad_norm = 0.5\n",
    "arg_log_interval = 10\n",
    "arg_save_interval = 100\n",
    "arg_eval_interval = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    assert arg_algo in ['a2c', 'ppo']\n",
    "\n",
    "    update_factor = arg_num_steps * arg_num_processes\n",
    "    num_updates = int(arg_num_frames) // update_factor\n",
    "    lr_update_schedule = None if arg_lr_schedule is None else arg_lr_schedule // update_factor\n",
    "\n",
    "    torch.manual_seed(arg_seed)\n",
    "    if arg_cuda:\n",
    "        torch.cuda.manual_seed(arg_seed)\n",
    "    np.random.seed(arg_seed)\n",
    "\n",
    "    try:\n",
    "        os.makedirs(arg_log_dir)\n",
    "    except OSError:\n",
    "        files = glob.glob(os.path.join(arg_log_dir, '*.monitor.csv'))\n",
    "        try:\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    eval_log_dir = arg_log_dir + \"_eval\"\n",
    "    try:\n",
    "        os.makedirs(eval_log_dir)\n",
    "    except OSError:\n",
    "        files = glob.glob(os.path.join(eval_log_dir, '*.monitor.csv'))\n",
    "        try:\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    torch.set_num_threads(1)\n",
    "    device = torch.device(\"cuda:0\" if arg_cuda else \"cpu\")\n",
    "\n",
    "    train_envs = make_vec_envs(\n",
    "        arg_env_name, arg_seed, arg_num_processes, arg_gamma, arg_no_norm, arg_num_stack,\n",
    "        arg_log_dir, device, allow_early_resets=False)\n",
    "\n",
    "    if arg_eval_interval:\n",
    "        eval_envs = make_vec_envs(\n",
    "            arg_env_name, arg_seed + arg_num_processes, arg_num_processes, arg_gamma,\n",
    "            arg_no_norm, arg_num_stack, eval_log_dir, device,\n",
    "            allow_early_resets=True, eval=True)\n",
    "\n",
    "        if eval_envs.venv.__class__.__name__ == \"VecNormalize\":\n",
    "            eval_envs.venv.ob_rms = train_envs.venv.ob_rms\n",
    "    else:\n",
    "        eval_envs = None\n",
    "\n",
    "    actor_critic = create_policy(\n",
    "        train_envs.observation_space,\n",
    "        nn_kwargs={\n",
    "            'batch_norm': True,\n",
    "            'hidden_size': 512,\n",
    "        },\n",
    "        train=True)\n",
    "    if arg_load_path and load:\n",
    "        print(\"Loading in previous model\")\n",
    "        try:\n",
    "            path_ = \"./trained_models/a2c/PommeFFACompetitionFast-v0.pt\"\n",
    "            if arg_algo.startswith('ppo'):\n",
    "                path_ = \"./trained_models/ppo/PommeFFACompetitionFast-v0.pt\"\n",
    "\n",
    "            state_dict, ob_rms = torch.load(path_)\n",
    "            actor_critic.load_state_dict(state_dict)\n",
    "        except:\n",
    "            print(\"Wrong path!\")\n",
    "            exit(1)\n",
    "    actor_critic.to(device)\n",
    "\n",
    "    if arg_algo.startswith('a2c'):\n",
    "        agent = algo.A2C(\n",
    "            actor_critic, arg_value_loss_coef,\n",
    "            arg_entropy_coef,\n",
    "            lr=arg_lr, lr_schedule=lr_update_schedule,\n",
    "            eps=arg_eps, alpha=arg_alpha,\n",
    "            max_grad_norm=arg_max_grad_norm)\n",
    "    elif arg_algo.startswith('ppo'):\n",
    "        agent = algo.OUR_PPO(  # PPO HER!\n",
    "            actor_critic, arg_clip_param, arg_ppo_epoch, arg_num_mini_batch,\n",
    "            arg_value_loss_coef, arg_entropy_coef,\n",
    "            lr=arg_lr, lr_schedule=lr_update_schedule,\n",
    "            eps=arg_eps,\n",
    "            max_grad_norm=arg_max_grad_norm)\n",
    "\n",
    "    rollouts = RolloutStorage(\n",
    "        arg_num_steps, arg_num_processes,\n",
    "        train_envs.observation_space.shape,\n",
    "        train_envs.action_space)\n",
    "\n",
    "    obs = train_envs.reset()\n",
    "    rollouts.obs[0].copy_(obs)\n",
    "    rollouts.to(device)\n",
    "\n",
    "    episode_rewards = deque(maxlen=10)\n",
    "\n",
    "    start = time.time()\n",
    "    for j in range(num_updates):\n",
    "        for step in range(arg_num_steps):\n",
    "            # Sample actions\n",
    "            with torch.no_grad():\n",
    "                value, action, action_log_prob = actor_critic.act(\n",
    "                    rollouts.obs[step],\n",
    "                    rollouts.masks[step])\n",
    "\n",
    "            # Obser reward and next obs\n",
    "            obs, reward, done, infos = train_envs.step(action)\n",
    "\n",
    "            for info in infos:\n",
    "                if 'episode' in info.keys():\n",
    "                    rew = info['episode']['r']\n",
    "                    episode_rewards.append(rew)\n",
    "\n",
    "            # If done then clean the history of observations.\n",
    "            masks = torch.tensor([[0.0] if done_ else [1.0] for done_ in done], device=device)\n",
    "            rollouts.insert(obs, action, action_log_prob, value, reward, masks)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_value = actor_critic.get_value(rollouts.obs[-1],\n",
    "                                                rollouts.masks[-1]).detach()\n",
    "\n",
    "        rollouts.compute_returns(next_value, arg_use_gae, arg_gamma, arg_tau)\n",
    "\n",
    "        value_loss, action_loss, dist_entropy, other_metrics = agent.update(rollouts, j)\n",
    "\n",
    "        rollouts.after_update()\n",
    "\n",
    "        if j % arg_save_interval == 0 and arg_save_dir != \"\":\n",
    "            save_path = os.path.join(arg_save_dir, arg_algo)\n",
    "            try:\n",
    "                os.makedirs(save_path)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "            # Save model\n",
    "            save_model = actor_critic\n",
    "            if arg_cuda:\n",
    "                save_model = copy.deepcopy(actor_critic).cpu()\n",
    "\n",
    "            save_model = [save_model.state_dict(),\n",
    "                          hasattr(train_envs.venv, 'ob_rms') and train_envs.venv.ob_rms or None]\n",
    "\n",
    "            torch.save(save_model, os.path.join(save_path, arg_env_name + \".pt\"))\n",
    "\n",
    "        total_num_steps = (j + 1) * update_factor\n",
    "\n",
    "        if j % arg_log_interval == 0 and len(episode_rewards) > 1:\n",
    "            end = time.time()\n",
    "            print(\"Updates {}, num timesteps {}, FPS {}, last {} mean/median reward {:.1f}/{:.1f}, \"\n",
    "                  \"min / max reward {:.1f}/{:.1f}, value/action loss {:.5f}/{:.5f}\".\n",
    "                  format(j, total_num_steps,\n",
    "                         int(total_num_steps / (end - start)),\n",
    "                         len(episode_rewards),\n",
    "                         np.mean(episode_rewards),\n",
    "                         np.median(episode_rewards),\n",
    "                         np.min(episode_rewards),\n",
    "                         np.max(episode_rewards), dist_entropy,\n",
    "                         value_loss, action_loss), end=', ' if other_metrics else '\\n')\n",
    "            with open(\"train_results_\" + arg_algo + \".txt\", \"a+\") as res_file:\n",
    "                to_print = \"{},{}\\n\".format(total_num_steps, np.mean(episode_rewards))\n",
    "                res_file.write(to_print)\n",
    "\n",
    "        if arg_eval_interval and len(episode_rewards) > 1 and j > 0 and j % arg_eval_interval == 0:\n",
    "            eval_episode_rewards = []\n",
    "\n",
    "            obs = eval_envs.reset()\n",
    "            eval_masks = torch.zeros(arg_num_processes, 1, device=device)\n",
    "\n",
    "            while len(eval_episode_rewards) < 50:\n",
    "                with torch.no_grad():\n",
    "                    _, action, _ = actor_critic.act(\n",
    "                        obs, eval_masks, deterministic=True)\n",
    "\n",
    "                # Obser reward and next obs\n",
    "                obs, reward, done, infos = eval_envs.step(action)\n",
    "                eval_masks = torch.tensor([[0.0] if done_ else [1.0] for done_ in done], device=device)\n",
    "                for info in infos:\n",
    "                    if 'episode' in info.keys():\n",
    "                        eval_episode_rewards.append(info['episode']['r'])\n",
    "            with open(\"eval_results_\" + arg_algo + \".txt\", \"a+\") as res_file:\n",
    "                to_print = \"{},{}\\n\".format(total_num_steps, np.mean(eval_episode_rewards))\n",
    "                res_file.write(to_print)\n",
    "            print(\"Evaluation using {} episodes: mean reward {:.5f}\\n\".format(len(eval_episode_rewards),\n",
    "                                                                              np.mean(eval_episode_rewards)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to train the model, here it is:\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from models.factory import create_policy\n",
    "from envs import make_vec_envs\n",
    "\n",
    "import SearchAgent_2 as SearchAgent\n",
    "import pommerman\n",
    "from pommerman import agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arg_hide = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def render():\n",
    "    torch.set_num_threads(1)\n",
    "    device = torch.device(\"cuda:0\" if arg_cuda else \"cpu\")\n",
    "\n",
    "    num_env = 1\n",
    "    env = make_vec_envs(arg_env_name, arg_seed + 1000,\n",
    "                        num_env, gamma=None, no_norm=arg_no_norm,\n",
    "                        num_stack=arg_num_stack, log_dir=None,\n",
    "                        device=device, eval=True, allow_early_resets=False)\n",
    "\n",
    "    # Get a render function\n",
    "    render_func = None\n",
    "    tmp_env = env\n",
    "    while True:\n",
    "        if hasattr(tmp_env, 'envs'):\n",
    "            render_func = tmp_env.envs[0].render\n",
    "            break\n",
    "        elif hasattr(tmp_env, 'venv'):\n",
    "            tmp_env = tmp_env.venv\n",
    "        elif hasattr(tmp_env, 'env'):\n",
    "            tmp_env = tmp_env.env\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # We need to use the same statistics for normalization as used in training\n",
    "    state_dict, ob_rms = torch.load(arg_load_path)\n",
    "\n",
    "    actor_critic = create_policy(\n",
    "        env.observation_space,\n",
    "        nn_kwargs={\n",
    "            'batch_norm': True,\n",
    "            'hidden_size': 512,\n",
    "        },\n",
    "        train=False)\n",
    "\n",
    "    actor_critic.load_state_dict(state_dict)\n",
    "    actor_critic.to(device)\n",
    "\n",
    "    masks = torch.zeros(num_env, 1).to(device)\n",
    "\n",
    "    obs = env.reset()\n",
    "\n",
    "    if arg_hide:\n",
    "        render_func = None\n",
    "\n",
    "    if render_func is not None:\n",
    "        render_func('human')\n",
    "\n",
    "    if arg_env_name.find('Bullet') > -1:\n",
    "        import pybullet as p\n",
    "\n",
    "        torsoId = -1\n",
    "        for i in range(p.getNumBodies()):\n",
    "            if p.getBodyInfo(i)[0].decode() == \"torso\":\n",
    "                torsoId = i\n",
    "\n",
    "    rewards = []\n",
    "    wins = 0\n",
    "    deaths = 0\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    while True:\n",
    "        step = step + 1\n",
    "        with torch.no_grad():\n",
    "            value, action, _ = actor_critic.act(\n",
    "                obs, masks, deterministic=True)\n",
    "\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        masks = torch.tensor([[0.0] if done_ else [1.0] for done_ in done]).to(device)\n",
    "\n",
    "        if arg_env_name.find('Bullet') > -1:\n",
    "            if torsoId > -1:\n",
    "                distance = 5\n",
    "                yaw = 0\n",
    "                humanPos, humanOrn = p.getBasePositionAndOrientation(torsoId)\n",
    "                p.resetDebugVisualizerCamera(distance, yaw, -20, humanPos)\n",
    "\n",
    "        for i, d in enumerate(done):\n",
    "            if d:\n",
    "                rewards.append(reward[i].item())\n",
    "                if reward[i].item() > 0:\n",
    "                    wins = wins + 1\n",
    "                if reward[i].item() < 0 and step <= 800:\n",
    "                    deaths = deaths + 1\n",
    "                print(\"Game ended in {} steps, total games played: {}. Win rate: {}. Survival rate {}\".format(step-1, len(rewards), float(wins) / len(rewards), 1.0-float(deaths)/len(rewards)))\n",
    "                step = 0\n",
    "\n",
    "        if render_func is not None:\n",
    "            render_func('human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create env, our agent starts at:  1\n",
      "Game ended in 245 steps, total games played: 1. Win rate: 1.0. Survival rate 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAllocatorMemoryException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36m_safe_alloc\u001b[0;34m(self, count)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mallocation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAllocatorMemoryException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\allocation.py\u001b[0m in \u001b[0;36malloc\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[1;32mraise\u001b[0m \u001b[0mAllocatorMemoryException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapacity\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfree_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAllocatorMemoryException\u001b[0m: 260",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c218df185f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c8c476d01907>\u001b[0m in \u001b[0;36mrender\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrender_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mrender_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pommerman\\envs\\v0.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close, record_pngs_dir, record_json_dir, do_sleep)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_viewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_viewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_bombs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bombs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_viewer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrecord_pngs_dir\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pommerman\\graphics.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0magents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_dead_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_main_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0magents_board\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_agents_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pommerman\\graphics.py\u001b[0m in \u001b[0;36mrender_main_board\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0my_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBORDER_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mtop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboard_top\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBORDER_SIZE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender_agents_board\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pommerman\\graphics.py\u001b[0m in \u001b[0;36mrender_board\u001b[0;34m(self, board, x_offset, y_offset, size, top)\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mtile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 sprite = pyglet.sprite.Sprite(\n\u001b[0;32m--> 304\u001b[0;31m                     tile, x, y, batch=self._batch, group=LAYER_FOREGROUND)\n\u001b[0m\u001b[1;32m    305\u001b[0m                 \u001b[0msprites\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msprite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msprites\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\sprite.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img, x, y, blend_src, blend_dest, batch, group, usage, subpixel)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_usage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0musage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subpixel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubpixel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_vertex_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\sprite.py\u001b[0m in \u001b[0;36m_create_vertex_list\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             self._vertex_list = self._batch.add(4, GL_QUADS, self._group,\n\u001b[0;32m--> 394\u001b[0;31m                 vertex_format, 'c4B', ('t3f', self._texture.tex_coords))\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_position\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\__init__.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, count, mode, group, *data)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[1;31m# Create vertex list and initialize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mvlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minitial_arrays\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mvlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_attribute_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, count)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mVertexList\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         '''\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_alloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mVertexList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexdomain.py\u001b[0m in \u001b[0;36m_safe_alloc\u001b[0;34m(self, count)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_attributes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                 \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapacity\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_capacity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malloc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\graphics\\vertexbuffer.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mglPushClientAttrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGL_CLIENT_VERTEX_ARRAY_BIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mglBindBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0mglBufferData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mglPopClientAttrib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Programs\\Anaconda3\\lib\\site-packages\\pyglet\\gl\\lib.py\u001b[0m in \u001b[0;36merrcheck\u001b[0;34m(result, func, arguments)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mGLException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No GL context; create a Window first'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gl_begin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglGetError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgluErrorString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
